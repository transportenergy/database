{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magli\\AppData\\Local\\Temp\\ipykernel_22172\\3305849434.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns = {column_names_lower[index]:expected_column}, inplace = True)\n",
      "C:\\Users\\magli\\AppData\\Local\\Temp\\ipykernel_22172\\3305849434.py:229: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns = {column_names_lower[index]:expected_column}, inplace = True)\n",
      "C:\\Users\\magli\\AppData\\Local\\Temp\\ipykernel_22172\\3305849434.py:285: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '!' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_out_put.loc[index, ['Data quality flag']] = '!'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "import pycountry\n",
    "import math\n",
    "\n",
    "class AtoWorkbook:\n",
    "            \n",
    "    # Function that loads rule book\n",
    "    def load_rule_book(self, file_name: str):\n",
    "        with open(file_name) as f:\n",
    "            SOURCES = yaml.load(f, Loader=SafeLoader)\n",
    "        return SOURCES\n",
    "\n",
    "    # Function that loads yaml file containing mapping of ISO_Code with Regions\n",
    "    def populate_regions(self, file_name: str):\n",
    "        REGION = {}\n",
    "        # Populate the map from the regions.yaml file\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            for region_name, info in yaml.load(file, Loader=SafeLoader).items():\n",
    "                REGION.update({c: region_name for c in info[\"countries\"]})\n",
    "        return REGION\n",
    "    \n",
    "    #Function that extracts Country and Region using ISO_Code\n",
    "    \n",
    "    # Function that mapps ISO_Code to Country and Region\n",
    "    def country_region_mapping(self, economy_code, regions):\n",
    "        COUNTRY = dict()\n",
    "        region_country_list = []\n",
    "\n",
    "        country = pycountry.countries.get(alpha_3=economy_code)    \n",
    "        country_name = country.name\n",
    "        region_country_list = [country_name, regions[economy_code]]\n",
    "        COUNTRY.update({economy_code: region_country_list})                       \n",
    "        \n",
    "        return COUNTRY\n",
    "    \n",
    "    # Function that returns ruleID, indicator_name and dictionary\n",
    "    def get_rule_id(self, rule_book:dict):\n",
    "        rule_id = \"Txxx\"\n",
    "        valid_id_found = False\n",
    "\n",
    "        for key, value in rule_book.items():        \n",
    "            for new_key, new_val in value.items():\n",
    "                if new_key == \"name\":\n",
    "                    indicator_name = new_val                \n",
    "                    dataset_name_split = new_val.split('-')\n",
    "                    list_length = len(dataset_name_split)\n",
    "                    for index in range(list_length):\n",
    "                        if \"Sales\" in dataset_name_split[index]:\n",
    "                            valid_id_found = True\n",
    "                            rule_id = key\n",
    "                            break    \n",
    "                        else:\n",
    "                            valid_id_found = False\n",
    "\n",
    "            if valid_id_found:            \n",
    "               break\n",
    "\n",
    "        return rule_id, value, indicator_name\n",
    "    \n",
    "    # Function that returns Vehicle Type\n",
    "    def get_vehicle_type(self, mode:str, item_value: dict , dataset_name: str):\n",
    "        \"\"\"Determine 'Vehicle type' from 'mode' and 'indicator'\"\"\"\n",
    "\n",
    "        splited_indicator_name = dataset_name.split('-')\n",
    "        first_indicator_word = splited_indicator_name[0]\n",
    "        mode_indicator = mode + \" \" +  first_indicator_word\n",
    "        mode_indicator = mode_indicator.rstrip()            \n",
    "        VehicleType = \"LDV\"\n",
    "        vehicle_type_found = False\n",
    "        \n",
    "        for new_key, new_val in item_value.items():\n",
    "            if new_key == \"VehicleType\":\n",
    "                # Check if new_val is a dictionary\n",
    "                if isinstance(new_val, dict):\n",
    "                    for key1, value1 in new_val.items():\n",
    "                        if mode_indicator in key1:                                                            \n",
    "                            VehicleType = value1              \n",
    "                            vehicle_type_found= True\n",
    "                            break \n",
    "                            \n",
    "        return VehicleType\n",
    "\n",
    "    # Function that returns Variable Type\n",
    "    def get_variable_type(self, service_name: str, indicator_name: str):\n",
    "        \"\"\"Determine 'variable' using Service name.\n",
    "\n",
    "        The rules implemented are:\n",
    "        ============================================= ===== ============\n",
    "        Variable types                                 \n",
    "        ============================================= ===== ============\n",
    "            Variable\n",
    "            The variable is set to Passenger Activity.\n",
    "        ============================================= ===== ============\n",
    "        \"\"\"\n",
    "        variable = None  # Initialize variable to None\n",
    "\n",
    "        if service_name == \"Passenger\" and \"LDV Sales\" in indicator_name:\n",
    "            variable = \"Sales (New Vehicles)\"\n",
    "\n",
    "        return variable\n",
    "    \n",
    "    def get_unit_and_unit_factor(self, item_value: dict, unit_name: str):\n",
    "        \"\"\"Determine 'expected unit' and 'unit factor' from 'Unit'.\n",
    "\n",
    "        The rules implemented are:\n",
    "\n",
    "        ============================================= ===== ============\n",
    "        Unit                                    \n",
    "        ============================================= ===== ============\n",
    "        The unit is changed from Number to 10^6 vehicle / yr.\n",
    "        # Unit: \"Number to 10^6 vehicle / yr\"\n",
    "        ============================================= ===== ============\n",
    "        \"\"\"\n",
    "        unit = \"NA\"\n",
    "        unit_factor = 1     \n",
    "        unit_found = False    \n",
    "            \n",
    "        for new_key, new_val in item_value.items():            \n",
    "            if new_key == \"Unit\":\n",
    "                for key1, value1 in new_val.items():\n",
    "                    if unit_name in value1:\n",
    "                        unit = \"10^6 vehicle / yr\"\n",
    "                        unit_factor = 1000000  # Set unit_factor to the correct value\n",
    "                        unit_found= True\n",
    "                        break\n",
    "            if unit_found:\n",
    "                break\n",
    "            \n",
    "        return unit, unit_factor\n",
    "\n",
    "    \n",
    "    #Function that extracts upper part of the dataframe\n",
    "    #And returns [mode_value, source_value, service_value, unit_value, indicator_value, sheet_name]\n",
    "    def extract_upper_part_one(self, df_upper: pd.DataFrame):\n",
    "        column_names= list(df_upper.columns.values)\n",
    "\n",
    "        upper_part_attributes = []\n",
    "\n",
    "        # Accessing the \"Mode\" attribute\n",
    "        mode_value = df_upper.loc[4, column_names[1]]\n",
    "        upper_part_attributes.append(mode_value)\n",
    "\n",
    "        source_long_name = \"Asian Transport Outlook National Database\"\n",
    "        if column_names[1] == source_long_name:\n",
    "           source_short_name = \"ATO\"\n",
    "\n",
    "        # Accessing the \"Source:\" attribute\n",
    "        source_value = source_short_name + \"2023 \" + df_upper.loc[1, column_names[1]]\n",
    "        upper_part_attributes.append(source_value)    \n",
    "        \n",
    "        # Accessing the \"Sector or Service\" attribute\n",
    "        service_value = df_upper.loc[5, column_names[1]]\n",
    "        upper_part_attributes.append(service_value)\n",
    "\n",
    "        # Accessing the \"Unit\" attribute\n",
    "        unit_value = df_upper.loc[6, column_names[1]]\n",
    "        upper_part_attributes.append(unit_value)\n",
    "\n",
    "        # Accessing the \"Indicator\" attribute\n",
    "        indicator_value = df_upper.loc[0, column_names[1]]\n",
    "        upper_part_attributes.append(indicator_value)\n",
    "\n",
    "        # Accessing the \"Indicator ATO Code:\" attribute\n",
    "        sheet_name = df_upper.loc[1, column_names[1]]\n",
    "        upper_part_attributes.append(sheet_name)\n",
    "\n",
    "        return upper_part_attributes \n",
    "      \n",
    "    # Function that extracts remaing upper part of the dataframe\n",
    "    # And returns [vehicle_type, variable_type, unit, unit_factor, rule_id]\n",
    "    def extract_upper_part_two(self, upper_part_attributes: list, rule_book: dict):\n",
    "        #[mode_value, source_value, service_value, unit_value, indicator_value, sheet_name]\n",
    "        remaining_part_attributes = []\n",
    "\n",
    "        rule_id, item_value, indicator_name = self.get_rule_id(rule_book)\n",
    "\n",
    "        vehicleType = self.get_vehicle_type(upper_part_attributes[0], item_value, indicator_name)\n",
    "        \n",
    "        unit, unit_factor = self.get_unit_and_unit_factor(item_value, upper_part_attributes[3])\n",
    "\n",
    "        variable_type = self.get_variable_type(upper_part_attributes[2], upper_part_attributes[4])\n",
    "\n",
    "        remaining_part_attributes.append(vehicleType)    \n",
    "        remaining_part_attributes.append(variable_type)\n",
    "        remaining_part_attributes.append(unit)\n",
    "        remaining_part_attributes.append(unit_factor)\n",
    "        remaining_part_attributes.append(rule_id)\n",
    "\n",
    "        return remaining_part_attributes\n",
    "\n",
    "    #Function that updates correct coulumns to the lower dataframe\n",
    "    def process_lower_part(self, df: pd.DataFrame):\n",
    "        column_names_lower= list(df.columns.values)\n",
    "        columun_length = len(column_names_lower)\n",
    "        valid_column_length = 0\n",
    "        updated_column_names= []\n",
    "\n",
    "        for index in range(columun_length):\n",
    "            #remove extra white space from the end of a string\n",
    "            column_names_lower[index].rstrip()\n",
    "\n",
    "            #For columns Economy Code and Economy Name\n",
    "            if index < 2: \n",
    "                expected_column = df.loc[13, column_names_lower[index]]\n",
    "\n",
    "                # Replace columun names of the dataframe with the correct column name\n",
    "                df.rename(columns = {column_names_lower[index]:expected_column}, inplace = True)\n",
    "                updated_column_names.append(expected_column)\n",
    "\n",
    "            #For columns from 1990 upto 2022\n",
    "            else:\n",
    "                expected_column = df.loc[13, column_names_lower[index]]\n",
    "                same_type = isinstance(expected_column, str)\n",
    "\n",
    "                #Incase the column value is different from string\n",
    "                if not same_type:\n",
    "                    expected_column = math.trunc(expected_column) #remove decimal numbers  \n",
    "                    expected_column = str(expected_column) #int into string casting\n",
    "                \n",
    "                try:\n",
    "                    valid_columun = int(expected_column) #string into int casting\n",
    "                    int_type = isinstance(valid_columun, int)\n",
    "                    if int_type:\n",
    "                        # Replace columun names of the dataframe with the correct column name\n",
    "                        df.rename(columns = {column_names_lower[index]:expected_column}, inplace = True)\n",
    "                        updated_column_names.append(expected_column) \n",
    "                except ValueError:\n",
    "                    print(\"Invalid columun name for : \" + expected_column)\n",
    "\n",
    "        df_lower_updated = df[updated_column_names].copy()\n",
    "        df_lower_new = df_lower_updated.drop([13])\n",
    "\n",
    "        return df_lower_new, updated_column_names\n",
    "\n",
    "    # Function that updates the output dataframe\n",
    "    def update_master_data(self, df_out_put: pd.DataFrame, df: pd.DataFrame, column_list_names,\n",
    "                        upper_attributes, remaining_attributes, regions):\n",
    "        #[mode_value, source_value, service_value, unit_value, indicator_value, sheet_name]\n",
    "        #[vehicle_type, variable_type, unit, unit_factor, rule_id, Data quality flag]\n",
    "\n",
    "        # Iterate over columns and reorder them\n",
    "        column_order = ['Country', 'ISO Code', 'Region', 'Variable', 'Unit', 'Vehicle Type', \n",
    "                    'Technology', 'Fuel', 'ID', 'Mode', 'Source', 'Service'] + column_list_names[2:] + ['Data quality flag']\n",
    "        for index, row in df.iterrows():\n",
    "            country_new = self.country_region_mapping(row['Economy Code'], regions)\n",
    "            num_of_country =  len(country_new[row['Economy Code']])\n",
    "\n",
    "            if num_of_country == 1:\n",
    "                single_name = country_new[row['Economy Code']]\n",
    "                for common_name in single_name:\n",
    "                    region_name = common_name\n",
    "                    country_name = common_name          \n",
    "            else:\n",
    "                country_name, region_name = country_new[row['Economy Code']]\n",
    "            \n",
    "            df_out_put.loc[index, ['Country']] = country_name\n",
    "            df_out_put.loc[index, ['ISO Code']] = row['Economy Code']\n",
    "            df_out_put.loc[index, ['Region']] = region_name\n",
    "\n",
    "            df_out_put.loc[index, ['Variable']] = remaining_attributes[1]\n",
    "            df_out_put.loc[index, ['Unit']] = remaining_attributes[2]\n",
    "            df_out_put.loc[index, ['Vehicle Type']] = remaining_attributes[0]\n",
    "            df_out_put.loc[index, ['Technology']] = \"All\"\n",
    "            df_out_put.loc[index, ['Fuel']] = \"All\"\n",
    "            df_out_put.loc[index, ['ID']] = remaining_attributes[4]\n",
    "\n",
    "            df_out_put.loc[index, ['Mode']] = upper_attributes[0]\n",
    "            df_out_put.loc[index, ['Source']] = upper_attributes[1]\n",
    "            df_out_put.loc[index, ['Service']] = upper_attributes[2]\n",
    "\n",
    "            col_length = len(df.columns)\n",
    "    \n",
    "            for idx in range(col_length):\n",
    "                if idx > 1:\n",
    "                    # Check if the value is a numeric type before applying math.isnan\n",
    "                    if pd.notna(df.loc[index, column_list_names[idx]]):\n",
    "                        unit_value = pd.to_numeric(df.loc[index, column_list_names[idx]], errors='coerce')\n",
    "                        final_unit = unit_value / remaining_attributes[3]\n",
    "                        df_out_put.loc[index, column_list_names[idx]] = final_unit\n",
    "            # Add the \"Data quality flag\" column with a desired value (e.g., \"!\" or \"!!\")\n",
    "            df_out_put.loc[index, ['Data quality flag']] = '!'\n",
    "\n",
    "        # Reorder the columns\n",
    "        df_out_put = df_out_put[column_order]\n",
    "                \n",
    "        return df_out_put\n",
    "        \n",
    "    # Function that extract and process the input files and save the final data  \n",
    "    def process_input_data(self, workbook_file: str, master_file: str, regions_file: str, source_file: str):\n",
    "        # Steps followed for extracting and cleaning the dataset\n",
    "        #Step 1) Load both ATO workbook excel sheet and master dataset csv files into Dataframes\n",
    "        df = pd.read_excel(open(workbook_excel_file, 'rb'),sheet_name='TAS-VEP-005(2)')\n",
    "      \n",
    "        # Load the master data CSV file\n",
    "        master_df = pd.read_csv(master_csv_file)\n",
    "        master_column_names= list(master_df.columns.values)\n",
    "\n",
    "        #Step 2) Create a new dataframe using master dataset column names\n",
    "        df_out_put = pd.DataFrame(columns=master_column_names)\n",
    "\n",
    "        #Step 3) Separate the ATO workbook dataframe into two parts\n",
    "        #a) Upper part of the data frame containg 8 rows \n",
    "        df_upper = df.head(8)\n",
    "\n",
    "        #The function returns a list of \n",
    "        #[mode_value, source_value, service_value, unit_value, indicator_value, sheet_name]\n",
    "        upper_part_attributes = self.extract_upper_part_one(df_upper)\n",
    "\n",
    "        regions = self.populate_regions(regions_file)\n",
    "\n",
    "        rule_book = self.load_rule_book(source_file)\n",
    "\n",
    "        remaining_part_attributes = self.extract_upper_part_two(upper_part_attributes, rule_book)\n",
    "\n",
    "        # b) Lower part of the dataframe containing the remaining rows \n",
    "        # extract lower part of the dataframe\n",
    "        df_lower = df.iloc[13:65]\n",
    "\n",
    "        df_lower_new, updated_column_names = self.process_lower_part(df_lower)\n",
    "\n",
    "        master_df_output = self.update_master_data(df_out_put, df_lower_new, updated_column_names,\n",
    "                                        upper_part_attributes, remaining_part_attributes, regions)    \n",
    "\n",
    "        master_df_output.to_csv(\"Output_data_\"+ upper_part_attributes[5] + \".csv\", index=False)\n",
    "\n",
    "           \n",
    "# Name and path of input files\n",
    "workbook_excel_file = r\"ATO Workbook (TRANSPORT ACTIVITY & SERVICES (TAS))2023.xlsx\"\n",
    "master_csv_file = r\"master dataset.csv\"\n",
    "regions_file = r\"regions.yaml\"\n",
    "source_file = r\"sources.yaml\"\n",
    "\n",
    "# Check if the Excel file exists\n",
    "if os.path.isfile(workbook_excel_file):\n",
    "    \n",
    "    # Process the input files and save output as csv file\n",
    "    atoWorkBook = AtoWorkbook()\n",
    "    atoWorkBook.process_input_data(workbook_excel_file, master_csv_file, regions_file, source_file)\n",
    "    print(\"File is found.\")\n",
    "else:\n",
    "    print(\"File is not found on the specified path!!\")\n",
    "\n",
    "##<<<<<<<<<<<<<<<<<<<<< //////////////////////// >>>>>>>>>>>>>>>>>>>>>>>>##\n",
    "##<<<<<<<<<<<<<<<<<<<<< Programe ends here >>>>>>>>>>>>>>>>>>>>>>>>##\n",
    "##<<<<<<<<<<<<<<<<<<<<< //////////////////////// >>>>>>>>>>>>>>>>>>>>>>>>##        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
